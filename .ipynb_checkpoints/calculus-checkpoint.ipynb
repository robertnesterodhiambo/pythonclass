{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Task 1 – Gradient Descent using NumPy (20%)\n",
    "\n",
    "##  Part 1 (6 marks):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \\( f(r) = \\frac{{(r - 7)^3}}{3} \\)\n",
    "\n",
    "   To differentiate this function \\( f(r) \\) with respect to \\( r \\), we'll use the power rule and chain rule. The power rule states that if we have a term of the form \\( (u)^n \\), its derivative is \\( n \\cdot (u)^{n-1} \\). The chain rule states that if we have a composite function \\( f(g(x)) \\), its derivative is \\( f'(g(x)) \\cdot g'(x) \\).\n",
    "\n",
    "   Let \\( u = r - 7 \\). Then \\( f(r) = \\frac{{u^3}}{3} \\).\n",
    "\n",
    "   \\[ \\frac{d}{dr}f(r) = \\frac{d}{dr}\\left(\\frac{u^3}{3}\\right) = \\frac{1}{3} \\cdot \\frac{d}{dr}(u^3) \\]\n",
    "\n",
    "   Applying the power rule to \\( u^3 \\):\n",
    "\n",
    "   \\[ \\frac{d}{dr}f(r) = \\frac{1}{3} \\cdot 3u^2 \\cdot \\frac{du}{dr} \\]\n",
    "\n",
    "   Now, \\( \\frac{du}{dr} = \\frac{d}{dr}(r - 7) = 1 \\).\n",
    "\n",
    "   Therefore,\n",
    "\n",
    "   \\[ \\frac{d}{dr}f(r) = u^2 = (r - 7)^2 \\]\n",
    "\n",
    "   So, the derivative of \\( f(r) \\) with respect to \\( r \\) is \\( (r - 7)^2 \\).\n",
    "\n",
    "2. \\( f(s) = (4s - 20)^2 + (2s - 10)^2 \\)\n",
    "\n",
    "   To differentiate this function \\( f(s) \\) with respect to \\( s \\), we'll apply the power rule.\n",
    "\n",
    "   \\[ \\frac{d}{ds}f(s) = 2(4s - 20) \\cdot \\frac{d}{ds}(4s - 20) + 2(2s - 10) \\cdot \\frac{d}{ds}(2s - 10) \\]\n",
    "\n",
    "   Applying the power rule to \\( (4s - 20) \\) and \\( (2s - 10) \\):\n",
    "\n",
    "   \\[ \\frac{d}{ds}f(s) = 2(4s - 20) \\cdot 4 + 2(2s - 10) \\cdot 2 \\]\n",
    "\n",
    "   Simplifying,\n",
    "\n",
    "   \\[ \\frac{d}{ds}f(s) = 8(4s - 20) + 4(2s - 10) \\]\n",
    "\n",
    "   \\[ \\frac{d}{ds}f(s) = 32s - 160 + 8s - 40 \\]\n",
    "\n",
    "   \\[ \\frac{d}{ds}f(s) = 40s - 200 \\]\n",
    "\n",
    "   So, the derivative of \\( f(s) \\) with respect to \\( s \\) is \\( 40s - 200 \\).\n",
    "\n",
    "3. \\( f(t) = \\left(\\frac{{4t^2}}{t} - 12\\right)^2 \\)\n",
    "\n",
    "   To differentiate this function \\( f(t) \\) with respect to \\( t \\), we'll again apply the power rule.\n",
    "\n",
    "   Let \\( u = \\frac{{4t^2}}{t} - 12 \\). Then \\( f(t) = u^2 \\).\n",
    "\n",
    "   \\[ \\frac{d}{dt}f(t) = 2u \\cdot \\frac{du}{dt} \\]\n",
    "\n",
    "   Now, \\( \\frac{du}{dt} = \\frac{d}{dt}\\left(\\frac{{4t^2}}{t} - 12\\right) = \\frac{d}{dt}(4t - 12) = 4 \\).\n",
    "\n",
    "   Therefore,\n",
    "\n",
    "   \\[ \\frac{d}{dt}f(t) = 2u \\cdot 4 \\]\n",
    "\n",
    "   \\[ \\frac{d}{dt}f(t) = 8u \\]\n",
    "\n",
    "   Now, \\( u = \\frac{{4t^2}}{t} - 12 = 4t - 12 \\).\n",
    "\n",
    "   So,\n",
    "\n",
    "   \\[ \\frac{d}{dt}f(t) = 8(4t - 12) \\]\n",
    "\n",
    "   \\[ \\frac{d}{dt}f(t) = 32t - 96 \\]\n",
    "\n",
    "   So, the derivative of \\( f(t) \\) with respect to \\( t \\) is \\( 32t - 96 \\).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2 (12 marks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the error function\n",
    "def error_function(r, s, t):\n",
    "    return (r - 7)**3 + (4*s - 20)**2 + (2*s - 10)**2 + ((4*t**2)/t - 12)**2\n",
    "\n",
    "# Define the gradient of the error function\n",
    "def gradient_error(r, s, t):\n",
    "    grad_r = 3 * (r - 7)**2\n",
    "    grad_s = 24 * s - 120\n",
    "    grad_t = (-32*t**4 + 64*t**3 + 96*t**2 - 192*t) / (t**3)\n",
    "    return np.array([grad_r, grad_s, grad_t])\n",
    "\n",
    "# Initialize the algorithm with initial values\n",
    "r = 8\n",
    "s = 1\n",
    "t = 4\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "\n",
    "# Apply gradient descent algorithm\n",
    "for i in range(num_iterations):\n",
    "    gradient = gradient_error(r, s, t)\n",
    "    r -= learning_rate * gradient[0]\n",
    "    s -= learning_rate * gradient[1]\n",
    "    t -= learning_rate * gradient[2]\n",
    "\n",
    "# Compute the final error\n",
    "final_error = error_function(r, s, t)\n",
    "print(\"Final error:\", final_error)\n",
    "\n",
    "# Print the final values of r, s, and t\n",
    "print(\"Final values after gradient descent:\")\n",
    "print(\"r =\", r)\n",
    "print(\"s =\", s)\n",
    "print(\"t =\", t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2b (2 marks):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the true values of \\( r \\), \\( s \\), and \\( t \\) such that \\( E = y^2 = 0 \\), we need to solve the equation \\( E(r, s, t) = 0 \\) analytically. This means finding the exact solutions where the error function is equal to zero.\n",
    "\n",
    "Given the error function \\( E = y^2 \\), where \\( y = f(r, s, t) = (r - 7)^3 + (4s - 20)^2 + (2s - 10)^2 + \\left(\\frac{{4t^2}}{t} - 12\\right)^2 \\), we need to solve \\( y = 0 \\) to find the true values of \\( r \\), \\( s \\), and \\( t \\) where \\( E = 0 \\).\n",
    "\n",
    "Let's set up the equation \\( y = 0 \\) and solve it for \\( r \\), \\( s \\), and \\( t \\) separately:\n",
    "\n",
    "1. For \\( r \\):\n",
    "\\[ (r - 7)^3 = 0 \\]\n",
    "\\[ r - 7 = 0 \\]\n",
    "\\[ r = 7 \\]\n",
    "\n",
    "2. For \\( s \\):\n",
    "\\[ (4s - 20)^2 + (2s - 10)^2 = 0 \\]\n",
    "\n",
    "Both terms in the expression are squares, so they are always non-negative. The only way for the sum of two squares to be zero is if both squares are zero individually:\n",
    "\n",
    "\\[ (4s - 20)^2 = 0 \\]\n",
    "\\[ 4s - 20 = 0 \\]\n",
    "\\[ s - 5 = 0 \\]\n",
    "\\[ s = 5 \\]\n",
    "\n",
    "\\[ (2s - 10)^2 = 0 \\]\n",
    "\\[ 2s - 10 = 0 \\]\n",
    "\\[ s - 5 = 0 \\]\n",
    "\\[ s = 5 \\]\n",
    "\n",
    "So, \\( s = 5 \\).\n",
    "\n",
    "3. For \\( t \\):\n",
    "\\[ \\left(\\frac{{4t^2}}{t} - 12\\right)^2 = 0 \\]\n",
    "\\[ (4t - 12)^2 = 0 \\]\n",
    "\\[ 4t - 12 = 0 \\]\n",
    "\\[ t - 3 = 0 \\]\n",
    "\\[ t = 3 \\]\n",
    "\n",
    "Therefore, the true values of \\( r \\), \\( s \\), and \\( t \\) such that \\( E = 0 \\) are:\n",
    "\\[ r = 7 \\]\n",
    "\\[ s = 5 \\]\n",
    "\\[ t = 3 \\]\n",
    "\n",
    "These are the exact solutions where the error function is equal to zero, verified mathematically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Task 2 – Regression using PyTorch (35%)\n",
    "\n",
    "##  Part 1 (13 marks):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \\( y = 3(t^2 + 2)^2 \\), where \\( t = 2x + c \\)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize variables\n",
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "c = torch.tensor(1.0)\n",
    "\n",
    "# Define equation 1\n",
    "t = 2*x + c\n",
    "y = 3 * (t**2 + 2)**2\n",
    "\n",
    "# Calculate gradient\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient dy/dx\n",
    "print(\"Gradient dy/dx for equation 1:\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. \\( y = 3(s^3 + s) + 2c^4 \\), where \\( s = 2x \\)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reset gradient\n",
    "x.grad = None\n",
    "\n",
    "# Define equation 2\n",
    "s = 2*x\n",
    "y = 3 * (s**3 + s) + 2*c**4\n",
    "\n",
    "# Calculate gradient\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient dy/dx\n",
    "print(\"Gradient dy/dx for equation 2:\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. \\( y = 2t + c \\), where \\( t = (p^2 + 2p + 3)^2 \\), \\( p = 2r^3 + 3r \\), \\( r = 2q + 3 \\), \\( q = 2x + c \\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset gradient\n",
    "x.grad = None\n",
    "\n",
    "# Define equation 3\n",
    "q = 2*x + c\n",
    "r = 2*q + 3\n",
    "p = 2*r**3 + 3*r\n",
    "t = (p**2 + 2*p + 3)**2\n",
    "y = 2*t + c\n",
    "\n",
    "# Calculate gradient\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient dy/dx\n",
    "print(\"Gradient dy/dx for equation 3:\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
