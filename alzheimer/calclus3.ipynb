{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Task 3 – Neural Networks (35%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 18:48:44.278006: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 18:48:47.382730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 images belonging to 4 classes.\n",
      "Found 1279 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oem/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-03-20 18:48:50.169334: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-20 18:48:50.170867: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-03-20 18:48:50.216501: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 56229888 exceeds 10% of free system memory.\n",
      "2024-03-20 18:48:50.265149: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 56229888 exceeds 10% of free system memory.\n",
      "2024-03-20 18:48:50.280587: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 56229888 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 18:48:51.090902: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 56229888 exceeds 10% of free system memory.\n",
      "/home/oem/.local/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-03-20 18:48:52.500819: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 56229888 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 238ms/step - accuracy: 0.4622 - loss: 17.6065 - val_accuracy: 0.5238 - val_loss: 5.8924\n",
      "Epoch 2/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 236ms/step - accuracy: 0.5636 - loss: 3.6881 - val_accuracy: 0.5066 - val_loss: 2.9875\n",
      "Epoch 3/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 231ms/step - accuracy: 0.6273 - loss: 2.2970 - val_accuracy: 0.5387 - val_loss: 1.8211\n",
      "Epoch 4/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 233ms/step - accuracy: 0.7315 - loss: 0.9737 - val_accuracy: 0.5090 - val_loss: 5.5562\n",
      "Epoch 5/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 231ms/step - accuracy: 0.7577 - loss: 0.9645 - val_accuracy: 0.5270 - val_loss: 3.9780\n",
      "Epoch 6/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 227ms/step - accuracy: 0.7805 - loss: 0.7076 - val_accuracy: 0.5848 - val_loss: 2.3209\n",
      "Epoch 7/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 237ms/step - accuracy: 0.8226 - loss: 0.4894 - val_accuracy: 0.5684 - val_loss: 2.2796\n",
      "Epoch 8/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 236ms/step - accuracy: 0.8863 - loss: 0.3057 - val_accuracy: 0.5622 - val_loss: 3.1954\n",
      "Epoch 9/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 238ms/step - accuracy: 0.7108 - loss: 2.1564 - val_accuracy: 0.5747 - val_loss: 1.8515\n",
      "Epoch 10/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 237ms/step - accuracy: 0.8529 - loss: 0.3900 - val_accuracy: 0.5410 - val_loss: 2.7189\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oem/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 2s/step - accuracy: 0.4750 - loss: 1.1415 - val_accuracy: 0.5332 - val_loss: 0.9847\n",
      "Epoch 2/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 2s/step - accuracy: 0.6172 - loss: 0.8100 - val_accuracy: 0.6044 - val_loss: 0.9122\n",
      "Epoch 3/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 2s/step - accuracy: 0.8417 - loss: 0.3859 - val_accuracy: 0.6341 - val_loss: 1.0562\n",
      "Epoch 4/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 2s/step - accuracy: 0.9409 - loss: 0.1623 - val_accuracy: 0.5786 - val_loss: 1.5565\n",
      "Epoch 5/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 2s/step - accuracy: 0.9821 - loss: 0.0545 - val_accuracy: 0.6263 - val_loss: 2.2599\n",
      "Epoch 6/10\n",
      "\u001b[1m 66/161\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.0193"
     ]
    }
   ],
   "source": [
    "##  Part 1 (25 marks):\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (176, 208)  # Assuming image dimensions\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4\n",
    "EPOCHS = 10\n",
    "\n",
    "# Data preprocessing\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory='train',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory='test',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Simple Neural Network\n",
    "model_simple = models.Sequential([\n",
    "    layers.Flatten(input_shape=(*IMAGE_SIZE, 3)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model_simple.compile(optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "history_simple = model_simple.fit(train_generator,\n",
    "                                  epochs=EPOCHS,\n",
    "                                  validation_data=test_generator)\n",
    "\n",
    "# Convolutional Neural Network\n",
    "model_cnn = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(*IMAGE_SIZE, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model_cnn.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "history_cnn = model_cnn.fit(train_generator,\n",
    "                            epochs=EPOCHS,\n",
    "                            validation_data=test_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_simple.history['accuracy'], label='Simple NN Training Accuracy')\n",
    "plt.plot(history_simple.history['val_accuracy'], label='Simple NN Validation Accuracy')\n",
    "plt.plot(history_cnn.history['accuracy'], label='CNN Training Accuracy')\n",
    "plt.plot(history_cnn.history['val_accuracy'], label='CNN Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting training and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_simple.history['loss'], label='Simple NN Training Loss')\n",
    "plt.plot(history_simple.history['val_loss'], label='Simple NN Validation Loss')\n",
    "plt.plot(history_cnn.history['loss'], label='CNN Training Loss')\n",
    "plt.plot(history_cnn.history['val_loss'], label='CNN Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparing the number of parameters\n",
    "print(\"Number of parameters - Simple NN:\", model_simple.count_params())\n",
    "print(\"Number of parameters - CNN:\", model_cnn.count_params())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model Architecture:\n",
    "The simple neural network comprises only fully connected layers (Dense layers) and lacks convolutional or pooling layers. On the other hand, the convolutional neural network (CNN) incorporates convolutional layers followed by max-pooling layers. CNNs are well-suited for image classification tasks as they can effectively capture spatial hierarchies of features from images.\n",
    "\n",
    "### 2. Training and Validation Accuracy/Loss:\n",
    "In terms of training and validation accuracy/loss, the CNN is expected to outperform the simple neural network. This expectation arises from the CNN's ability to learn hierarchical features, which often leads to better generalization. Therefore, one would anticipate observing higher validation accuracy and lower validation loss for the CNN compared to the simple neural network over the epochs.\n",
    "\n",
    "### 3. Number of Parameters:\n",
    "CNNs typically have more parameters compared to simple neural networks due to the presence of convolutional layers. As expected, the CNN is anticipated to have a higher number of trainable parameters compared to the simple neural network. This increased parameter count reflects the complexity of the CNN architecture, which allows it to learn intricate patterns in the data.\n",
    "\n",
    "### 4. Computational Complexity:\n",
    "Considering computational complexity, CNNs are generally more computationally intensive, especially during training and inference. This heightened computational demand stems from the convolutional operations performed across multiple layers. Therefore, one would expect the CNN to require more computational resources compared to the simple neural network.\n",
    "\n",
    "### 5. Performance on Test Data:\n",
    "Finally, evaluating the performance of both models on the test dataset is crucial to assess their generalization ability. While the CNN is expected to perform better due to its ability to capture hierarchical features, it is essential to validate this expectation through empirical testing. Comparing the test accuracy and other relevant metrics will provide insights into how well each model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (10 marks):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Effect of Learning Rate:**\n",
    "   - Learning Rate of 0.00000001: This is an extremely small learning rate, which means the model updates its parameters very slowly. It may lead to very slow convergence or even convergence to a suboptimal solution due to slow updates.\n",
    "   - Learning Rate of 10: This is an extremely large learning rate, which means the model updates its parameters very quickly. It may lead to overshooting the optimal solution, causing the loss function to diverge or fluctuate wildly.\n",
    "   - Advantages of a Higher Learning Rate:\n",
    "     - Faster convergence: With a higher learning rate, the model converges to the optimal solution more quickly.\n",
    "     - Works well for simple problems: Higher learning rates may be suitable for simpler problems with smooth loss landscapes.\n",
    "   - Disadvantages of a Higher Learning Rate:\n",
    "     - Risk of divergence: Too high a learning rate may cause the loss function to diverge or fluctuate wildly, making it difficult to converge to an optimal solution.\n",
    "     - Overshooting: Large updates can cause the optimizer to overshoot the optimal solution, leading to oscillations or instability.\n",
    "   - Advantages of a Lower Learning Rate:\n",
    "     - Stability: Lower learning rates typically result in more stable training with smaller updates, reducing the risk of divergence.\n",
    "     - Precision: Smaller updates allow the optimizer to fine-tune the parameters more precisely, potentially leading to better convergence.\n",
    "   - Disadvantages of a Lower Learning Rate:\n",
    "     - Slow convergence: Very low learning rates may lead to slow convergence, requiring more iterations to reach the optimal solution.\n",
    "     - Prone to getting stuck in local minima: In complex loss landscapes, lower learning rates may cause the optimizer to get stuck in local minima or saddle points.\n",
    "\n",
    "2. **Effect of Batch Size:**\n",
    "   - Advantages of a Higher Batch Size:\n",
    "     - Faster computation: With a larger batch size, more samples are processed simultaneously, leading to faster training times, especially on hardware optimized for parallel processing like GPUs.\n",
    "     - Smoother gradients: Larger batch sizes tend to produce smoother gradient estimates, which can lead to more stable training and convergence.\n",
    "   - Disadvantages of a Higher Batch Size:\n",
    "     - Memory requirements: Larger batch sizes require more memory, which may limit the size of models or the number of samples that can be processed simultaneously.\n",
    "     - Generalization performance: Larger batch sizes may lead to poorer generalization performance, as the model may not see a diverse enough set of samples in each batch.\n",
    "   - Advantages of a Lower Batch Size:\n",
    "     - Improved generalization: Smaller batch sizes may lead to better generalization performance, as the model sees a more diverse set of samples in each batch, which can help prevent overfitting.\n",
    "     - More noise in gradients: Smaller batch sizes introduce more noise into gradient estimates, which can help the optimizer escape from local minima and explore the parameter space more effectively.\n",
    "   - Disadvantages of a Lower Batch Size:\n",
    "     - Slower convergence: Smaller batch sizes typically result in slower convergence, as each update is based on a smaller subset of the training data.\n",
    "     - Less efficient computation: Smaller batch sizes may lead to less efficient computation, especially on hardware optimized for parallel processing, as fewer samples are processed simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
