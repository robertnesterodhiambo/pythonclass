{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Task 1 – Gradient Descent using NumPy (20%)\n",
    "\n",
    "##  Part 1 (6 marks):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \\( f(r) = \\frac{{(r - 7)^3}}{3} \\)\n",
    "\n",
    "   To differentiate this function \\( f(r) \\) with respect to \\( r \\), we'll use the power rule and chain rule. The power rule states that if we have a term of the form \\( (u)^n \\), its derivative is \\( n \\cdot (u)^{n-1} \\). The chain rule states that if we have a composite function \\( f(g(x)) \\), its derivative is \\( f'(g(x)) \\cdot g'(x) \\).\n",
    "\n",
    "   Let \\( u = r - 7 \\). Then \\( f(r) = \\frac{{u^3}}{3} \\).\n",
    "\n",
    "   \\[ \\frac{d}{dr}f(r) = \\frac{d}{dr}\\left(\\frac{u^3}{3}\\right) = \\frac{1}{3} \\cdot \\frac{d}{dr}(u^3) \\]\n",
    "\n",
    "   Applying the power rule to \\( u^3 \\):\n",
    "\n",
    "   \\[ \\frac{d}{dr}f(r) = \\frac{1}{3} \\cdot 3u^2 \\cdot \\frac{du}{dr} \\]\n",
    "\n",
    "   Now, \\( \\frac{du}{dr} = \\frac{d}{dr}(r - 7) = 1 \\).\n",
    "\n",
    "   Therefore,\n",
    "\n",
    "   \\[ \\frac{d}{dr}f(r) = u^2 = (r - 7)^2 \\]\n",
    "\n",
    "   So, the derivative of \\( f(r) \\) with respect to \\( r \\) is \\( (r - 7)^2 \\).\n",
    "\n",
    "2. \\( f(s) = (4s - 20)^2 + (2s - 10)^2 \\)\n",
    "\n",
    "   To differentiate this function \\( f(s) \\) with respect to \\( s \\), we'll apply the power rule.\n",
    "\n",
    "   \\[ \\frac{d}{ds}f(s) = 2(4s - 20) \\cdot \\frac{d}{ds}(4s - 20) + 2(2s - 10) \\cdot \\frac{d}{ds}(2s - 10) \\]\n",
    "\n",
    "   Applying the power rule to \\( (4s - 20) \\) and \\( (2s - 10) \\):\n",
    "\n",
    "   \\[ \\frac{d}{ds}f(s) = 2(4s - 20) \\cdot 4 + 2(2s - 10) \\cdot 2 \\]\n",
    "\n",
    "   Simplifying,\n",
    "\n",
    "   \\[ \\frac{d}{ds}f(s) = 8(4s - 20) + 4(2s - 10) \\]\n",
    "\n",
    "   \\[ \\frac{d}{ds}f(s) = 32s - 160 + 8s - 40 \\]\n",
    "\n",
    "   \\[ \\frac{d}{ds}f(s) = 40s - 200 \\]\n",
    "\n",
    "   So, the derivative of \\( f(s) \\) with respect to \\( s \\) is \\( 40s - 200 \\).\n",
    "\n",
    "3. \\( f(t) = \\left(\\frac{{4t^2}}{t} - 12\\right)^2 \\)\n",
    "\n",
    "   To differentiate this function \\( f(t) \\) with respect to \\( t \\), we'll again apply the power rule.\n",
    "\n",
    "   Let \\( u = \\frac{{4t^2}}{t} - 12 \\). Then \\( f(t) = u^2 \\).\n",
    "\n",
    "   \\[ \\frac{d}{dt}f(t) = 2u \\cdot \\frac{du}{dt} \\]\n",
    "\n",
    "   Now, \\( \\frac{du}{dt} = \\frac{d}{dt}\\left(\\frac{{4t^2}}{t} - 12\\right) = \\frac{d}{dt}(4t - 12) = 4 \\).\n",
    "\n",
    "   Therefore,\n",
    "\n",
    "   \\[ \\frac{d}{dt}f(t) = 2u \\cdot 4 \\]\n",
    "\n",
    "   \\[ \\frac{d}{dt}f(t) = 8u \\]\n",
    "\n",
    "   Now, \\( u = \\frac{{4t^2}}{t} - 12 = 4t - 12 \\).\n",
    "\n",
    "   So,\n",
    "\n",
    "   \\[ \\frac{d}{dt}f(t) = 8(4t - 12) \\]\n",
    "\n",
    "   \\[ \\frac{d}{dt}f(t) = 32t - 96 \\]\n",
    "\n",
    "   So, the derivative of \\( f(t) \\) with respect to \\( t \\) is \\( 32t - 96 \\).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2 (12 marks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final error: nan\n",
      "Final values after gradient descent:\n",
      "r = 7.032150655915842\n",
      "s = 4.999999999999998\n",
      "t = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42168/3175500887.py:11: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  grad_t = (-32*t**4 + 64*t**3 + 96*t**2 - 192*t) / (t**3)\n",
      "/tmp/ipykernel_42168/3175500887.py:11: RuntimeWarning: invalid value encountered in scalar add\n",
      "  grad_t = (-32*t**4 + 64*t**3 + 96*t**2 - 192*t) / (t**3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the error function\n",
    "def error_function(r, s, t):\n",
    "    return (r - 7)**3 + (4*s - 20)**2 + (2*s - 10)**2 + ((4*t**2)/t - 12)**2\n",
    "\n",
    "# Define the gradient of the error function\n",
    "def gradient_error(r, s, t):\n",
    "    grad_r = 3 * (r - 7)**2\n",
    "    grad_s = 24 * s - 120\n",
    "    grad_t = (-32*t**4 + 64*t**3 + 96*t**2 - 192*t) / (t**3)\n",
    "    return np.array([grad_r, grad_s, grad_t])\n",
    "\n",
    "# Initialize the algorithm with initial values\n",
    "r = 8\n",
    "s = 1\n",
    "t = 4\n",
    "learning_rate = 0.01\n",
    "num_iterations = 1000\n",
    "\n",
    "# Apply gradient descent algorithm\n",
    "for i in range(num_iterations):\n",
    "    gradient = gradient_error(r, s, t)\n",
    "    r -= learning_rate * gradient[0]\n",
    "    s -= learning_rate * gradient[1]\n",
    "    t -= learning_rate * gradient[2]\n",
    "\n",
    "# Compute the final error\n",
    "final_error = error_function(r, s, t)\n",
    "print(\"Final error:\", final_error)\n",
    "\n",
    "# Print the final values of r, s, and t\n",
    "print(\"Final values after gradient descent:\")\n",
    "print(\"r =\", r)\n",
    "print(\"s =\", s)\n",
    "print(\"t =\", t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2b (2 marks):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the true values of \\( r \\), \\( s \\), and \\( t \\) such that \\( E = y^2 = 0 \\), we need to solve the equation \\( E(r, s, t) = 0 \\) analytically. This means finding the exact solutions where the error function is equal to zero.\n",
    "\n",
    "Given the error function \\( E = y^2 \\), where \\( y = f(r, s, t) = (r - 7)^3 + (4s - 20)^2 + (2s - 10)^2 + \\left(\\frac{{4t^2}}{t} - 12\\right)^2 \\), we need to solve \\( y = 0 \\) to find the true values of \\( r \\), \\( s \\), and \\( t \\) where \\( E = 0 \\).\n",
    "\n",
    "Let's set up the equation \\( y = 0 \\) and solve it for \\( r \\), \\( s \\), and \\( t \\) separately:\n",
    "\n",
    "1. For \\( r \\):\n",
    "\\[ (r - 7)^3 = 0 \\]\n",
    "\\[ r - 7 = 0 \\]\n",
    "\\[ r = 7 \\]\n",
    "\n",
    "2. For \\( s \\):\n",
    "\\[ (4s - 20)^2 + (2s - 10)^2 = 0 \\]\n",
    "\n",
    "Both terms in the expression are squares, so they are always non-negative. The only way for the sum of two squares to be zero is if both squares are zero individually:\n",
    "\n",
    "\\[ (4s - 20)^2 = 0 \\]\n",
    "\\[ 4s - 20 = 0 \\]\n",
    "\\[ s - 5 = 0 \\]\n",
    "\\[ s = 5 \\]\n",
    "\n",
    "\\[ (2s - 10)^2 = 0 \\]\n",
    "\\[ 2s - 10 = 0 \\]\n",
    "\\[ s - 5 = 0 \\]\n",
    "\\[ s = 5 \\]\n",
    "\n",
    "So, \\( s = 5 \\).\n",
    "\n",
    "3. For \\( t \\):\n",
    "\\[ \\left(\\frac{{4t^2}}{t} - 12\\right)^2 = 0 \\]\n",
    "\\[ (4t - 12)^2 = 0 \\]\n",
    "\\[ 4t - 12 = 0 \\]\n",
    "\\[ t - 3 = 0 \\]\n",
    "\\[ t = 3 \\]\n",
    "\n",
    "Therefore, the true values of \\( r \\), \\( s \\), and \\( t \\) such that \\( E = 0 \\) are:\n",
    "\\[ r = 7 \\]\n",
    "\\[ s = 5 \\]\n",
    "\\[ t = 3 \\]\n",
    "\n",
    "These are the exact solutions where the error function is equal to zero, verified mathematically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Task 2 – Regression using PyTorch (35%)\n",
    "\n",
    "##  Part 1 (13 marks):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \\( y = 3(t^2 + 2)^2 \\), where \\( t = 2x + c \\)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize variables\n",
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "c = torch.tensor(1.0)\n",
    "\n",
    "# Define equation 1\n",
    "t = 2*x + c\n",
    "y = 3 * (t**2 + 2)**2\n",
    "\n",
    "# Calculate gradient\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient dy/dx\n",
    "print(\"Gradient dy/dx for equation 1:\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. \\( y = 3(s^3 + s) + 2c^4 \\), where \\( s = 2x \\)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reset gradient\n",
    "x.grad = None\n",
    "\n",
    "# Define equation 2\n",
    "s = 2*x\n",
    "y = 3 * (s**3 + s) + 2*c**4\n",
    "\n",
    "# Calculate gradient\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient dy/dx\n",
    "print(\"Gradient dy/dx for equation 2:\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. \\( y = 2t + c \\), where \\( t = (p^2 + 2p + 3)^2 \\), \\( p = 2r^3 + 3r \\), \\( r = 2q + 3 \\), \\( q = 2x + c \\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset gradient\n",
    "x.grad = None\n",
    "\n",
    "# Define equation 3\n",
    "q = 2*x + c\n",
    "r = 2*q + 3\n",
    "p = 2*r**3 + 3*r\n",
    "t = (p**2 + 2*p + 3)**2\n",
    "y = 2*t + c\n",
    "\n",
    "# Calculate gradient\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient dy/dx\n",
    "print(\"Gradient dy/dx for equation 3:\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.12.4)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch)\n",
      "  Using cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Downloading torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/755.6 MB\u001b[0m \u001b[31m31.1 kB/s\u001b[0m eta \u001b[36m6:45:24\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install --user torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
